{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined, not worked\n",
    "class Generator(tf.keras.Model):\n",
    "    '''\n",
    "        Generator\n",
    "    '''\n",
    "    def __init__(self, noise_dim=NOISE_DIM):\n",
    "        super(Generator, self).__init__(name='')\n",
    "        # initial 4 * 4\n",
    "        self.blocks = Sequential([Input(noise_dim),\n",
    "                            Dense(4*4*512, kernel_initializer=random_normal, bias_initializer='zeros'),\n",
    "                            Reshape((4, 4, 512)),\n",
    "                            Conv2D(512, (3, 3), strides=1, padding='same', kernel_initializer=random_normal, bias_initializer='zeros'),\n",
    "                            PixelNormalization(),\n",
    "                            LeakyReLU(),], name='Initial_Block')\n",
    "        \n",
    "        self.block_list = [self.blocks,\n",
    "                          upsample_block(input_shape=(4, 4, 512),filters=512, kernel_size=3, strides=1,\n",
    "                                         padding='same', activation=tf.nn.leaky_relu, name='Up_{}x{}'.format(8, 8)),\n",
    "                          upsample_block(input_shape=(8, 8, 512),filters=512, kernel_size=3, strides=1,\n",
    "                                         padding='same', activation=tf.nn.leaky_relu, name='Up_{}x{}'.format(16, 16)),\n",
    "                          upsample_block(input_shape=(16, 16, 512),filters=512, kernel_size=3, strides=1,\n",
    "                                         padding='same', activation=tf.nn.leaky_relu, name='Up_{}x{}'.format(32, 32)),\n",
    "                          upsample_block(input_shape=(32, 32, 512),filters=256, kernel_size=3, strides=1,\n",
    "                                         padding='same', activation=tf.nn.leaky_relu, name='Up_{}x{}'.format(64, 64)),\n",
    "                          upsample_block(input_shape=(64, 64, 256),filters=128, kernel_size=3, strides=1,\n",
    "                                         padding='same', activation=tf.nn.leaky_relu, name='Up_{}x{}'.format(128, 128)),\n",
    "                          upsample_block(input_shape=(128, 128, 128),filters=64, kernel_size=3, strides=1,\n",
    "                                         padding='same', activation=tf.nn.leaky_relu, name='Up_{}x{}'.format(256, 256)),\n",
    "                          upsample_block(input_shape=(256, 256, 64),filters=32, kernel_size=3, strides=1,\n",
    "                                         padding='same', activation=tf.nn.leaky_relu, name='Up_{}x{}'.format(512, 512)),]\n",
    "                              \n",
    "        self.stable_block_index = 0\n",
    "        self.total_blocks_length = len(self.block_list)\n",
    "        \n",
    "        self.to_rgb_list = [to_rgb_block((4, 4, 512), filters=3, kernel_size=1, strides=1,\n",
    "                                         padding='same', activation=tf.nn.tanh, name='ToRGB_{}x{}'.format(4, 4)),\n",
    "                                   to_rgb_block((8, 8, 512), filters=3, kernel_size=1, strides=1,\n",
    "                                         padding='same', activation=tf.nn.tanh, name='ToRGB_{}x{}'.format(8, 8)),\n",
    "                                   to_rgb_block((16, 16, 512), filters=3, kernel_size=1, strides=1,\n",
    "                                                 padding='same', activation=tf.nn.tanh, name='ToRGB_{}x{}'.format(16, 16)),\n",
    "                                   to_rgb_block((32, 32, 512), filters=3, kernel_size=1, strides=1,\n",
    "                                                 padding='same', activation=tf.nn.tanh, name='ToRGB_{}x{}'.format(32, 32)),\n",
    "                                   to_rgb_block((64, 64, 256), filters=3, kernel_size=1, strides=1,\n",
    "                                                 padding='same', activation=tf.nn.tanh, name='ToRGB_{}x{}'.format(64, 64)),\n",
    "                                   to_rgb_block((128, 128, 128), filters=3, kernel_size=1, strides=1,\n",
    "                                                 padding='same', activation=tf.nn.tanh, name='ToRGB_{}x{}'.format(128, 128)),\n",
    "                                   to_rgb_block((256, 256, 64), filters=3, kernel_size=1, strides=1,\n",
    "                                                 padding='same', activation=tf.nn.tanh, name='ToRGB_{}x{}'.format(256, 256)),\n",
    "                                   to_rgb_block((512, 512, 32), filters=3, kernel_size=1, strides=1,\n",
    "                                                 padding='same', activation=tf.nn.tanh, name='ToRGB_{}x{}'.format(512, 512)),]\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training=False, fade_in=False, alpha=0):\n",
    "        x = inputs\n",
    "        for block in self.block_list[0:self.stable_block_index+1]:\n",
    "            # Upsample blocks will have two output, but we only need the previous in normal phase\n",
    "            x= block(x)\n",
    "            if type(x) == list:\n",
    "                x = x[0]\n",
    "        if fade_in and (self.stable_block_index + 1 < self.total_blocks_length):\n",
    "            # Fade in stage\n",
    "            fade_in_index = self.stable_block_index + 1\n",
    "            x, up_x = self.block_list[fade_in_index](x)\n",
    "            x = self.to_rgb_list[fade_in_index](x)\n",
    "            up_x = self.to_rgb_list[fade_in_index](up_x)\n",
    "            x = (1- alpha) * up_x + alpha * x\n",
    "        else:\n",
    "            x = self.to_rgb_list[self.stable_block_index](x)\n",
    "        return x\n",
    "    \n",
    "    def equalize_learning_rate(self):\n",
    "        numpy_weights = self.get_weights()\n",
    "        new_weights = []\n",
    "        for i, weight in enumerate(self.weights):\n",
    "            if 'conv2d' in weight.name and 'bias' not in weight.name:\n",
    "                new_weights.append(compute_equal_lr(numpy_weights[i]))\n",
    "            else:\n",
    "                new_weights.append(numpy_weights[i])\n",
    "        self.set_weights(new_weights)\n",
    "        \n",
    "    def get_current_output_shape(self):\n",
    "        ## Not include To RGB\n",
    "        output_shapes = self.block_list[self.stable_block_index].get_output_shape_at(-1)\n",
    "        if type(output_shapes) == list:\n",
    "            output_shape = output_shapes[0][1:]\n",
    "        else:\n",
    "            output_shape = output_shapes[1:]\n",
    "        return output_shape\n",
    "    \n",
    "    def training_next_block(self):\n",
    "        if self.stable_block_index + 1 < self.total_blocks_length:\n",
    "            self.stable_block_index += 1\n",
    "        else:\n",
    "            print(\"Already reach the max resolution\")\n",
    "\n",
    "class Discriminator(tf.keras.Model):\n",
    "    '''\n",
    "        Generator\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__(name='')\n",
    "        # 4 * 4\n",
    "        self.final_block = Sequential([Input((4, 4, 512)),\n",
    "                            MinibatchSTDDEV(),\n",
    "                            Conv2D(512, (3, 3), strides=1, padding='same', kernel_initializer=random_normal, bias_initializer='zeros'),\n",
    "                            LeakyReLU(),\n",
    "                            Conv2D(512, (4, 4), strides=1, padding='valid', kernel_initializer=random_normal, bias_initializer='zeros'),\n",
    "                            LeakyReLU(),\n",
    "                            Flatten(),\n",
    "                            Dense(1, kernel_initializer=random_normal, bias_initializer='zeros')], name='FinalBlock')\n",
    "        \n",
    "        self.block_list = [downsample_block(input_shape=(512, 512, 32), filters=64, kernel_size=3, strides=1,\n",
    "                                            padding='same', activation=tf.nn.leaky_relu, name='Down_{}x{}'.format(512,512)),\n",
    "                                   downsample_block(input_shape=(256, 256, 64), filters=128, kernel_size=3, strides=1,\n",
    "                                            padding='same', activation=tf.nn.leaky_relu, name='Down_{}x{}'.format(256,256)),\n",
    "                                   downsample_block(input_shape=(128, 128, 128), filters=256, kernel_size=3, strides=1,\n",
    "                                            padding='same', activation=tf.nn.leaky_relu, name='Down_{}x{}'.format(128,128)),\n",
    "                                   downsample_block(input_shape=(64, 64, 256), filters=512, kernel_size=3, strides=1,\n",
    "                                            padding='same', activation=tf.nn.leaky_relu, name='Down_{}x{}'.format(64,64)),\n",
    "                                   downsample_block(input_shape=(32, 32, 512), filters=512, kernel_size=3, strides=1,\n",
    "                                            padding='same', activation=tf.nn.leaky_relu, name='Down_{}x{}'.format(32,32)),\n",
    "                                   downsample_block(input_shape=(16, 16, 512), filters=512, kernel_size=3, strides=1,\n",
    "                                            padding='same', activation=tf.nn.leaky_relu, name='Down_{}x{}'.format(16,16)),\n",
    "                                   downsample_block(input_shape=(8, 8, 512), filters=512, kernel_size=3, strides=1,\n",
    "                                            padding='same', activation=tf.nn.leaky_relu, name='Down_{}x{}'.format(8,8)),\n",
    "                                   self.final_block]\n",
    "        \n",
    "        self.stable_block_index = len(self.block_list) - 1\n",
    "        \n",
    "\n",
    "        self.from_rgb_list = [\n",
    "                            from_rgb_block(input_shape=(512, 512, 3), filters=32, down_sampled_filters=64, kernel_size=1, strides=1,\n",
    "                                             padding='same', activation=tf.nn.tanh, name='FromRGB_{}x{}'.format(512, 512)),\n",
    "                            from_rgb_block(input_shape=(256, 256, 3), filters=64, down_sampled_filters=128, kernel_size=1, strides=1,\n",
    "                                             padding='same', activation=tf.nn.tanh, name='FromRGB_{}x{}'.format(256, 256)),\n",
    "                            from_rgb_block(input_shape=(128, 128, 3), filters=128, down_sampled_filters=256, kernel_size=1, strides=1,\n",
    "                                             padding='same', activation=tf.nn.tanh, name='FromRGB_{}x{}'.format(128, 128)),\n",
    "                            from_rgb_block(input_shape=(64, 64, 3), filters=256, down_sampled_filters=512, kernel_size=1, strides=1,\n",
    "                                             padding='same', activation=tf.nn.tanh, name='FromRGB_{}x{}'.format(64, 64)),\n",
    "                            from_rgb_block(input_shape=(32, 32, 3), filters=512, down_sampled_filters=512, kernel_size=1, strides=1,\n",
    "                                             padding='same', activation=tf.nn.tanh, name='FromRGB_{}x{}'.format(32, 32)),\n",
    "                            from_rgb_block(input_shape=(16, 16, 3), filters=512, down_sampled_filters=512, kernel_size=1, strides=1,\n",
    "                                             padding='same', activation=tf.nn.tanh, name='FromRGB_{}x{}'.format(16, 16)),\n",
    "                             from_rgb_block(input_shape=(8, 8, 3), filters=512, down_sampled_filters=512, kernel_size=1, strides=1,\n",
    "                                             padding='same', activation=tf.nn.tanh, name='FromRGB_{}x{}'.format(8, 8)),\n",
    "                              from_rgb_block(input_shape=(4, 4, 3), filters=512, down_sampled_filters=512, kernel_size=1, strides=1,\n",
    "                                             padding='same', activation=tf.nn.tanh, name='FromRGB_{}x{}'.format(4, 4))]\n",
    "        \n",
    "    def call(self, inputs, training=False, fade_in=False, alpha=0):\n",
    "        x = inputs\n",
    "        \n",
    "        if fade_in and (self.stable_block_index - 1 >= 0):\n",
    "            # Fade in stage\n",
    "            fade_in_index = self.stable_block_index - 1\n",
    "            \n",
    "            x, down_x = self.from_rgb_list[fade_in_index](x)\n",
    "            x = self.block_list[fade_in_index](x)\n",
    "            \n",
    "            x = (1- alpha) * down_x + alpha * x\n",
    "        else:\n",
    "            # Using stable from rgb\n",
    "            x, _ = self.from_rgb_list[self.stable_block_index](x)\n",
    "        for block in self.block_list[self.stable_block_index:]:\n",
    "            x= block(x)\n",
    "        return x\n",
    "    \n",
    "    def equalize_learning_rate(self):\n",
    "        numpy_weights = self.get_weights()\n",
    "        new_weights = []\n",
    "        for i, weight in enumerate(self.weights):\n",
    "            if 'conv2d' in weight.name and 'bias' not in weight.name:\n",
    "                new_weights.append(compute_equal_lr(numpy_weights[i]))\n",
    "            else:\n",
    "                new_weights.append(numpy_weights[i])\n",
    "        self.set_weights(new_weights)\n",
    "    \n",
    "    def get_current_output_shape(self):\n",
    "        output_shapes = self.block_list[self.stable_block_index].get_output_shape_at(-1)\n",
    "        if type(output_shapes) == list:\n",
    "            output_shape = output_shapes[0][1:]\n",
    "        else:\n",
    "            output_shape = output_shapes[1:]\n",
    "        return output_shape\n",
    "                              \n",
    "    def training_next_block(self):\n",
    "        if self.stable_block_index - 1 >= 0:\n",
    "            self.stable_block_index -= 1\n",
    "        else:\n",
    "            print(\"Already reach the max resolution\")\n",
    "            \n",
    "    def set_stable_index(self, index):\n",
    "        self.stable_block_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualRLDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None,\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=1.0), bias_initializer='zeros', **kwargs):\n",
    "        super(EqualRLDense, self).__init__(**kwargs)\n",
    "        #[filter_height, filter_width, in_channels, out_channels]\n",
    "        self.units = units\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.activation = activation\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.weight_shape = (input_shape[-1], self.units)\n",
    "        self.fan_in, self.fan_out= compute_fans(self.weight_shape)\n",
    "        self.he_constant = tf.Variable(1.0 / np.sqrt(self.fan_in), dtype=tf.float32, trainable=False)\n",
    "        \n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                            shape=self.weight_shape,\n",
    "                             initializer=self.kernel_initializer,\n",
    "                             trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.weight_shape[-1],),\n",
    "                                 initializer=self.bias_initializer,\n",
    "                                 trainable=True)\n",
    "        \n",
    "        super(EqualRLDense, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        if training:  \n",
    "            eqrl_kernel = tf.multiply(self.kernel, self.he_constant)\n",
    "            outputs = K.dot(inputs, eqrl_kernel)\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias)\n",
    "        else:\n",
    "            outputs = K.dot(inputs, self.kernel)\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias)\n",
    "        if self.activation != None:\n",
    "            outputs = Activation(self.activation)(outputs)\n",
    "        return outputs\n",
    "\n",
    "class EqualRLConv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size=3, strides=1, padding='valid', activation=None,\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=1.0), bias_initializer='zeros', **kwargs):\n",
    "        super(EqualRLConv2D, self).__init__(**kwargs)\n",
    "        #[filter_height, filter_width, in_channels, out_channels]\n",
    "        self.strides = strides\n",
    "        self.kernel_size = kernel_size\n",
    "        self.filters = filters\n",
    "        self.padding = padding\n",
    "        self.data_format = 'channels_last'\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.activation = activation\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.weight_shape = (self.kernel_size, self.kernel_size, input_shape[-1], self.filters)\n",
    "        self.fan_in, self.fan_out= compute_fans(self.weight_shape)\n",
    "        \n",
    "        self.he_constant = tf.Variable(1.0 / np.sqrt(self.fan_in), dtype=tf.float32, trainable=False)\n",
    "        \n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                            shape=self.weight_shape,\n",
    "                             initializer=self.kernel_initializer,\n",
    "                             trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.weight_shape[-1],),\n",
    "                                 initializer=self.bias_initializer,\n",
    "                                 trainable=True)\n",
    "        \n",
    "        super(EqualRLConv2D, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            eqrl_kernel = tf.multiply(self.kernel, self.he_constant)\n",
    "            outputs = K.conv2d(inputs, eqrl_kernel,\n",
    "                         strides=self.strides,\n",
    "                        padding=self.padding,\n",
    "                        data_format=self.data_format)\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "        else:\n",
    "            outputs = K.conv2d(inputs, self.kernel,\n",
    "                         strides=self.strides,\n",
    "                        padding=self.padding,\n",
    "                        data_format=self.data_format)\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "        if self.activation != None:\n",
    "            outputs = Activation(self.activation)(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def upsample_block(x, in_filters, filters, kernel_size=3, strides=1, padding='valid', activation=tf.nn.leaky_relu, name=''):\n",
    "    '''\n",
    "        Upsampling + 2 Convolution-Activation\n",
    "    '''\n",
    "    upsample = UpSampling2D(size=2, interpolation='nearest')(x)\n",
    "#     if in_filters != filters:\n",
    "#         x = EqualRLConv2D(filters, kernel_size, strides, padding=padding,\n",
    "#                    kernel_initializer=kernel_initializer, bias_initializer='zeros', name=name+'_conv2d_0')(upsample)\n",
    "    upsample_x = EqualRLConv2D(filters, kernel_size, strides, padding=padding,\n",
    "                   kernel_initializer=kernel_initializer, bias_initializer='zeros', name=name+'_conv2d_1')(upsample)\n",
    "    x = PixelNormalization()(upsample_x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = EqualRLConv2D(filters, kernel_size, strides, padding=padding, kernel_initializer=kernel_initializer, bias_initializer='zeros', name=name+'_conv2d_2')(x)\n",
    "    x = PixelNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x, upsample\n",
    "\n",
    "def downsample_block(x, filters1, filters2, kernel_size=3, strides=1, padding='valid', activation=tf.nn.leaky_relu, name=''):\n",
    "    '''\n",
    "        2 Convolution-Activation + Downsampling\n",
    "    '''\n",
    "    x = EqualRLConv2D(filters1, kernel_size, strides, padding=padding,\n",
    "               kernel_initializer=kernel_initializer, bias_initializer='zeros', name=name+'_conv2d_1')(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = EqualRLConv2D(filters2, kernel_size, strides, padding=padding,\n",
    "               kernel_initializer=kernel_initializer, bias_initializer='zeros', name=name+'_conv2d_2')(x)\n",
    "    x = Activation(activation)(x)\n",
    "    downsample = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "    return downsample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
